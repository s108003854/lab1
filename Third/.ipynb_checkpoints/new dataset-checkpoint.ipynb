{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wasted two hours.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saw the movie today and thought it was a good ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A bit predictable.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Loved the casting of Jimmy Buffet as the scien...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score\n",
       "0  A very, very, very slow-moving, aimless movie ...    0.0\n",
       "1  Not sure who was more lost - the flat characte...    0.0\n",
       "2  Attempting artiness with black & white and cle...    0.0\n",
       "3       Very little music or anything to speak of.      0.0\n",
       "4  The best scene in the movie was when Gerardo i...    1.0\n",
       "5  The rest of the movie lacks art, charm, meanin...    0.0\n",
       "6                                Wasted two hours.      0.0\n",
       "7  Saw the movie today and thought it was a good ...    1.0\n",
       "8                               A bit predictable.      0.0\n",
       "9  Loved the casting of Jimmy Buffet as the scien...    1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import newdataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import helpers.data_mining_helpers as dmh\n",
    "\n",
    "imdb_data, imdb_score = dmh.load_data('imdb_labelled.txt')\n",
    "imdb_category_name = ['imdb' for i in range(len(imdb_data))]\n",
    "imdb_category = [0 for i in range(len(imdb_data))]\n",
    "\n",
    "amazon_data, amazon_score = dmh.load_data('amazon_cells_labelled.txt')\n",
    "amazon_category_name = ['amazon' for i in range(len(amazon_data))]\n",
    "amazon_category = [1 for i in range(len(amazon_data))]\n",
    "\n",
    "yelp_data, yelp_score = dmh.load_data('yelp_labelled.txt')\n",
    "yelp_category_name = ['yelp' for i in range(len(yelp_data))]\n",
    "yelp_category = [2 for i in range(len(yelp_data))]\n",
    "\n",
    "#merge 3 files in one data\n",
    "data = imdb_data + amazon_data + yelp_data\n",
    "score = imdb_score + amazon_score + yelp_score\n",
    "category_name = imdb_category_name + amazon_category_name + yelp_category_name\n",
    "category = imdb_category + amazon_category + yelp_category\n",
    "\n",
    "#Converting into Pandas Dataframe\n",
    "X = pd.DataFrame.from_records(data, columns= ['text'])\n",
    "\n",
    "#Add column\n",
    "X['score'] = score\n",
    "X['category_name'] = category_name\n",
    "X['category'] = category\n",
    "\n",
    "# a simple query\n",
    "X[0:10][[\"text\", \"score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature subset selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "# transorfmed the data into a term-document matrix\n",
    "X_counts = count_vect.fit_transform(X.text)\n",
    "\n",
    "\n",
    "#generate feature dictionary\n",
    "term_frequencies = {}\n",
    "for j in range(0,X_counts.shape[1]):\n",
    "    term_frequencies[count_vect.get_feature_names()[j]] = sum(X_counts[:,j].toarray())\n",
    "\n",
    "total = np.sum(np.sum(X_counts, axis=1))\n",
    "# X_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate feature by dictionary\n",
    "def convert_Content(content, freq_dict):\n",
    "    m = len(freq_dict)\n",
    "    key_index = list(term_frequencies.keys())\n",
    "    res = np.int_(np.zeros(m))\n",
    "    finds = re.findall('[A-Za-z]+', content)\n",
    "    for find in finds:\n",
    "        find=find.lower()\n",
    "        try:\n",
    "            i = key_index.index(find)\n",
    "            res[i]=freq_dict[find]\n",
    "#             print(i,freq_dict[find][0])\n",
    "        except:\n",
    "            continue\n",
    "    return res    \n",
    "\n",
    "# transform rawdata to feature\n",
    "def raw2feature(data, freq_dict):\n",
    "    n_train = data.shape[0]\n",
    "    m = len(freq_dict)\n",
    "    X_train = np.zeros((n_train,m));\n",
    "    for i in range(n_train):\n",
    "        X_train[i,:] = convert_Content(data.iloc[i], freq_dict)\n",
    "    return X_train\n",
    "\n",
    "\n",
    "key_index = list(term_frequencies.keys())\n",
    "\n",
    "X_freq =raw2feature(X['text'], term_frequencies)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5155 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate TF-IDF feature\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf2 = TfidfVectorizer()\n",
    "tfidf = tfidf2.fit_transform(X['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature: 0.8373333333333334\n",
      "word frequency feature: 0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split into trainset and testset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(tfidf, X['score'], test_size=0.25)\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.0)\n",
    "bnb.fit(X_train, Y_train)\n",
    "output_tfidf = bnb.score(X_test, Y_test)\n",
    "print(f'TF-IDF feature: {output_tfidf}')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_freq, X['score'], test_size=0.25)\n",
    "\n",
    "bnb = BernoulliNB(binarize=0.0)\n",
    "bnb.fit(X_train, Y_train)\n",
    "output_freq = bnb.score(X_test, Y_test)\n",
    "print(f'word frequency feature: {output_freq}')\n",
    "\n",
    "#字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
